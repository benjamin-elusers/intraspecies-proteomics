```{r load-data-proteomics, echo=F}
chap_cur=03
#load(here('output',sprintf('%02d-proteomics.rdata',chap_cur-1)))
```

# Data processing

Before normalizing intensities, we first need to discard some hits because they
are not suitable for analysis:

 1. contaminants (*identifier starts with CON*)
 2. reversed sequences (*identifier starts with REV*)
 3. multiple hits (*peptides matching several proteins*)
 4. not enough unique peptides (*low confidence identification (< 2 peptides)*)

```{r filter-data}
# Filter hits
ms1=filter_hits(ms0)
```

## Processing quantified intensities

Following the aim of this experiment, we wish to compare the variation of protein 
expression between strains. 

Once all samples have been filtered to exclude outliers hits, we can process the 
quantified intensities.

To avoid introducing potential biases, we will monitor the intensities over 4
stages of processing:

1. raw peptide intensities `int_raw`
2. lfq intensities `int_lfq`
3. normalization across strains (median equalization) `int_norm`
4. BPCA imputation on missing values (Bayesian PCA) `int_bpca`

Initially, samples may have large difference between raw peptide intensities 
for numerous technical and experimental reasons including but not limited to 
protein digestion (length), sample preparation, sample processing...

We typically use Label-Free Quantitation (LFQ) intensities [@maxlfq] which eliminates error
between samples by reconstructing the abundance profile based on all available
individual protein ratios.




Then, we discard proteins hits with missing values for XX strains or for YY replicates
types of media. 

Finally, we normalize the intensities by transforming to log2 and subtracting 
each sample's median. (cf formula below)


**Normalization method = Equalizing medians**

$$ norm.int_{sample} = log2(raw.int_{sample}) - log2(median_{sample}) $$
We filter out hits that contains missing values for either strains or replicates

```{r process-intensities}
# Process intensities

int_raw= ms1 %>% dplyr::select(uniprot=majority_protein_i_ds,starts_with("intensity_")) %>% 
            as.data.frame() %>% column_to_rownames('uniprot') %>%
            rename_with(everything(),.fn=gsub, pattern='intensity_', replacement='') %>%
            rename_with(.fn = str_to_upper)

int_lfq = ms1 %>% dplyr::select(uniprot=majority_protein_i_ds,starts_with("lfq")) %>% 
            #mutate(across(where(is.integer64), ~as.integer(.))) %>% # make sure to use numeric and not integer
            as.data.frame() %>% column_to_rownames('uniprot') %>%
            rename_with(everything(),.fn=gsub, pattern='lfq_intensity_', replacement='') %>%
            rename_with(.fn = str_to_upper)

int_md_norm = center_intensities(int_lfq, center='median', tolog2=T) %>% 
          as.data.frame() %>%
          rename_with(everything(),.fn =gsub, pattern='lfq_intensity_', replacement='') %>% 
          rename_with(.fn = str_to_upper)
         
# TRYING DIFFERENT NORMALIZATIONS SCHEME (NOT READY)
INT_NORM = normalize_intensities(int = int_raw, design = df.group)
df_all_norm <- INT_NORM@normalizations %>% 
               map2_df(.y = names(INT_NORM@normalizations),~mutate(id=rownames(.x),as_tibble(.x),method=.y))

TAB_NORM = kbl(names(INT_NORM@normalizations),row.names = T,col.names = 'Normalizations:',position = 'left') %>% 
            kable_paper("striped", full_width = F) %>% 
            kable_styling(position='left')  

            
int_norm = int_md_norm %>% rownames_to_column('uniprot') 
int_norm_ids = int_norm %>% dplyr::left_join(sc_identifiers,by=c('uniprot'='UNIPROT')) %>% filter(!duplicated(uniprot))
#compare_exp(log2(int_raw),int_loess_norm, all=T)
```

```{r impute-na}
library(MsCoreUtils)
int_norm_nona = int_norm %>% drop_na()
int_norm_bpca = MsCoreUtils::impute_bpca(int_norm) %>% as_tibble() %>% add_column(uniprot = int_norm_ids$uniprot)
```

```{r int-strains}
long_int_norm = pivot_longer(int_norm_bpca  , cols=-uniprot, values_to='int2use',
                             names_to = c('strain','bio','tech','day'),
                             names_pattern = "([^_]+)_([^_]+)_([^_]+)_([^_]+)") %>%
                group_by(strain,uniprot) %>% mutate(na_rep = sum.na(int2use))

# Intensities across strains  (default is average)
int_by_strain = pivot_wider(long_int_norm ,
              id_cols=uniprot,
              names_from = 'strain',
              names_glue = "{strain}",
              values_from = "int2use",
              values_fn=mean_
              )

na_by_strain = pivot_wider(long_int_norm,
              id_cols=uniprot,
              names_from = c('strain'),
              names_glue = "na_rep_{strain}",
              values_from = "int2use",
              values_fn=sum.na
              )

df_strains= left_join(int_by_strain,na_by_strain) %>% 
  rowwise %>%
  mutate( na_strains = sum.na(c_across(cols = starts_with('lfq_int'))) )

int_all = int_norm_bpca  %>% column_to_rownames('uniprot') %>% as.data.frame()

# Removing hits with missing values for more than one strain (using average intensities over replicates)
ms2= df_strains %>% filter(na_strains < 1)
int_filt_strains = ms2 %>% dplyr::select(-starts_with('na')) %>% column_to_rownames('uniprot') %>% as.data.frame()

# Save processed & normalized intensities data
#saveRDS(df_strains,here::here('output',sprintf("%02d-normalized-intensities.rds",chap_cur)))
```

```{r 02-save-data, echo=F}
save.image(here('output',sprintf("%02d-processed-data.rdata",chap_cur)))
```